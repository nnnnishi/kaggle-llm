#!/usr/bin/env python3
"""
3.4.5 Kaggleã¸ã®æ¶ã‘æ©‹
ã€Kaggle ã§ã¯ã˜ã‚ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«å…¥é–€ã€ç¬¬3ç« 

Kaggleã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³å½¢å¼ã§ã®æ¨è«–ã¨æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
"""

import os
import numpy as np
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# è¨­å®š
# =============================================================================
print("=" * 60)
print("3.4.5 Kaggleã¸ã®æ¶ã‘æ©‹")
print("=" * 60)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"\nğŸ–¥ï¸ Device: {device}")

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
if os.path.exists('/content/kaggle-llm/data'):
    DATA_DIR = '/content/kaggle-llm/data'
elif os.path.exists('/root/kaggle-llm/data'):
    DATA_DIR = '/root/kaggle-llm/data'
else:
    DATA_DIR = 'data'

# è¨­å®š
MODEL_NAME = 'microsoft/deberta-v3-small'
MAX_LENGTH = 256
BATCH_SIZE = 32

# =============================================================================
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹
# =============================================================================
class ReviewDataset(Dataset):
    def __init__(self, texts, tokenizer, max_length):
        self.texts = texts
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        
        encoding = self.tokenizer(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].squeeze(),
            'attention_mask': encoding['attention_mask'].squeeze(),
        }

# =============================================================================
# æ¨è«–é–¢æ•°
# =============================================================================
def predict(model, dataloader, device):
    model.eval()
    predictions = []
    probabilities = []
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc='Predicting'):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask
            )
            
            probs = torch.softmax(outputs.logits, dim=1)
            preds = torch.argmax(probs, dim=1)
            
            predictions.extend(preds.cpu().numpy())
            probabilities.extend(probs.cpu().numpy())
    
    return np.array(predictions), np.array(probabilities)

# =============================================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =============================================================================
def main():
    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nğŸ“ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
    test = pd.read_csv(f'{DATA_DIR}/test.csv')
    test['Review Text'] = test['Review Text'].fillna('')
    print(f"   ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test.shape}")
    
    # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ï¼†ãƒ¢ãƒ‡ãƒ«
    print(f"\nğŸ”¤ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿: {MODEL_NAME}")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForSequenceClassification.from_pretrained(
        MODEL_NAME,
        num_labels=5
    ).to(device)
    
    # æ³¨æ„: å®Ÿéš›ã®Kaggleæå‡ºã§ã¯ã€å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
    # model.load_state_dict(torch.load('model_weights.pth'))
    print("   âš ï¸ æ³¨æ„: äº‹å‰å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ï¼‰")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼†ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
    test_dataset = ReviewDataset(test['Review Text'].values, tokenizer, MAX_LENGTH)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)
    
    # æ¨è«–
    print("\nğŸ”® æ¨è«–å®Ÿè¡Œä¸­...")
    predictions, probabilities = predict(model, test_loader, device)
    
    # Rating ã¸ã®å¤‰æ› (0-indexed â†’ 1-indexed)
    ratings = predictions + 1
    
    # =============================================================================
    # æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    # =============================================================================
    print("\n" + "=" * 60)
    print("ğŸ“¤ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ")
    print("=" * 60)
    
    # åŸºæœ¬çš„ãªæå‡ºãƒ•ã‚¡ã‚¤ãƒ«
    submission = pd.DataFrame({
        'id': range(len(test)),
        'Rating': ratings
    })
    
    submission_path = f'{DATA_DIR}/submission_kaggle.csv'
    submission.to_csv(submission_path, index=False)
    print(f"\nğŸ’¾ ä¿å­˜: {submission_path}")
    
    # äºˆæ¸¬åˆ†å¸ƒã®ç¢ºèª
    print(f"\nğŸ“Š äºˆæ¸¬åˆ†å¸ƒ:")
    print(pd.Series(ratings).value_counts().sort_index())
    
    # ç¢ºç‡å€¤ã‚‚ä¿å­˜ï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç”¨ï¼‰
    probs_df = pd.DataFrame(
        probabilities,
        columns=[f'prob_class_{i+1}' for i in range(5)]
    )
    probs_path = f'{DATA_DIR}/test_probabilities.csv'
    probs_df.to_csv(probs_path, index=False)
    print(f"ğŸ’¾ ç¢ºç‡ä¿å­˜: {probs_path}")
    
    # =============================================================================
    # Kaggleæå‡ºã®ãƒ’ãƒ³ãƒˆ
    # =============================================================================
    print("\n" + "=" * 60)
    print("ğŸ’¡ Kaggleæå‡ºã®ãƒ’ãƒ³ãƒˆ")
    print("=" * 60)
    print("""
ã€æå‡ºæ‰‹é †ã€‘
1. submission_kaggle.csv ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
2. Kaggleã‚³ãƒ³ãƒšãƒšãƒ¼ã‚¸ã§ "Submit Predictions" ã‚’ã‚¯ãƒªãƒƒã‚¯
3. CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

ã€ã‚¹ã‚³ã‚¢å‘ä¸Šã®ãƒ’ãƒ³ãƒˆã€‘
- è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
- ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µï¼ˆåŒç¾©èªç½®æ›ãªã©ï¼‰
- ç–‘ä¼¼ãƒ©ãƒ™ãƒªãƒ³ã‚°
""")
    
    print("\nâœ… 3.4.5 å®Œäº†!")

if __name__ == '__main__':
    main()
