#!/usr/bin/env python3
"""
3.4 BERTç³»çµ±ã®ãƒ¢ãƒ‡ãƒ«
ã€Kaggle ã§ã¯ã˜ã‚ã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«å…¥é–€ã€ç¬¬3ç« 

DeBERTaã‚’ä½¿ã£ãŸãƒ†ã‚­ã‚¹ãƒˆåˆ†é¡
"""

import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import (
    AutoTokenizer, 
    AutoModelForSequenceClassification,
    get_linear_schedule_with_warmup
)
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score, f1_score, classification_report
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# è¨­å®š
# =============================================================================
print("=" * 60)
print("3.4 BERTç³»çµ±ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆDeBERTaï¼‰")
print("=" * 60)

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"\nğŸ–¥ï¸ Device: {device}")
if device.type == 'cuda':
    print(f"   GPU: {torch.cuda.get_device_name(0)}")

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
if os.path.exists('/content/kaggle-llm/data'):
    DATA_DIR = '/content/kaggle-llm/data'
elif os.path.exists('/root/kaggle-llm/data'):
    DATA_DIR = '/root/kaggle-llm/data'
else:
    DATA_DIR = 'data'

# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
MODEL_NAME = 'microsoft/deberta-v3-small'  # è»½é‡ç‰ˆDeBERTa
MAX_LENGTH = 256
BATCH_SIZE = 16
EPOCHS = 3
LEARNING_RATE = 2e-5
N_SPLITS = 5
RANDOM_STATE = 42

print(f"\nâš™ï¸ è¨­å®š:")
print(f"   Model: {MODEL_NAME}")
print(f"   Max Length: {MAX_LENGTH}")
print(f"   Batch Size: {BATCH_SIZE}")
print(f"   Epochs: {EPOCHS}")
print(f"   Learning Rate: {LEARNING_RATE}")

# =============================================================================
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹
# =============================================================================
class ReviewDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        
        encoding = self.tokenizer(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        item = {
            'input_ids': encoding['input_ids'].squeeze(),
            'attention_mask': encoding['attention_mask'].squeeze(),
        }
        
        if self.labels is not None:
            item['labels'] = torch.tensor(self.labels[idx] - 1, dtype=torch.long)  # 0-indexed
        
        return item

# =============================================================================
# å­¦ç¿’é–¢æ•°
# =============================================================================
def train_epoch(model, dataloader, optimizer, scheduler, device):
    model.train()
    total_loss = 0
    
    for batch in tqdm(dataloader, desc='Training', leave=False):
        optimizer.zero_grad()
        
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels
        )
        
        loss = outputs.loss
        total_loss += loss.item()
        
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        scheduler.step()
    
    return total_loss / len(dataloader)

def eval_epoch(model, dataloader, device):
    model.eval()
    predictions = []
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc='Evaluating', leave=False):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask
            )
            
            preds = torch.argmax(outputs.logits, dim=1)
            predictions.extend(preds.cpu().numpy())
    
    return np.array(predictions)

# =============================================================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =============================================================================
def main():
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print("\nğŸ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿...")
    train = pd.read_csv(f'{DATA_DIR}/train.csv')
    test = pd.read_csv(f'{DATA_DIR}/test.csv')
    
    train['Review Text'] = train['Review Text'].fillna('')
    test['Review Text'] = test['Review Text'].fillna('')
    
    print(f"   train: {train.shape}")
    print(f"   test:  {test.shape}")
    
    X = train['Review Text'].values
    y = train['Rating'].values
    X_test = test['Review Text'].values
    
    # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
    print(f"\nğŸ”¤ ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼èª­ã¿è¾¼ã¿: {MODEL_NAME}")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    
    # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
    print("\n" + "=" * 60)
    print("ğŸ”„ ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³")
    print("=" * 60)
    
    skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=RANDOM_STATE)
    
    oof_preds = np.zeros(len(train))
    test_preds = np.zeros((len(test), 5))
    scores = []
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):
        print(f"\n{'='*20} Fold {fold + 1}/{N_SPLITS} {'='*20}")
        
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]
        
        # Dataset & DataLoader
        train_dataset = ReviewDataset(X_train, y_train, tokenizer, MAX_LENGTH)
        val_dataset = ReviewDataset(X_val, y_val, tokenizer, MAX_LENGTH)
        test_dataset = ReviewDataset(X_test, None, tokenizer, MAX_LENGTH)
        
        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)
        test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)
        
        # ãƒ¢ãƒ‡ãƒ«
        model = AutoModelForSequenceClassification.from_pretrained(
            MODEL_NAME,
            num_labels=5
        ).to(device)
        
        # Optimizer & Scheduler
        optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)
        total_steps = len(train_loader) * EPOCHS
        scheduler = get_linear_schedule_with_warmup(
            optimizer,
            num_warmup_steps=int(total_steps * 0.1),
            num_training_steps=total_steps
        )
        
        # å­¦ç¿’
        best_f1 = 0
        for epoch in range(EPOCHS):
            print(f"\nEpoch {epoch + 1}/{EPOCHS}")
            
            train_loss = train_epoch(model, train_loader, optimizer, scheduler, device)
            val_preds = eval_epoch(model, val_loader, device)
            
            val_preds_class = val_preds + 1  # 1-indexed
            acc = accuracy_score(y_val, val_preds_class)
            f1 = f1_score(y_val, val_preds_class, average='macro')
            
            print(f"   Loss: {train_loss:.4f} | Accuracy: {acc:.4f} | Macro F1: {f1:.4f}")
            
            if f1 > best_f1:
                best_f1 = f1
                best_val_preds = val_preds_class.copy()
                
                # ãƒ†ã‚¹ãƒˆäºˆæ¸¬
                test_pred = eval_epoch(model, test_loader, device)
        
        # OOFäºˆæ¸¬ä¿å­˜
        oof_preds[val_idx] = best_val_preds
        
        # ãƒ†ã‚¹ãƒˆäºˆæ¸¬ï¼ˆone-hoté¢¨ã«åŠ ç®—ï¼‰
        for i, pred in enumerate(test_pred):
            test_preds[i, pred] += 1
        
        # ã‚¹ã‚³ã‚¢è¨˜éŒ²
        acc = accuracy_score(y_val, best_val_preds)
        f1 = f1_score(y_val, best_val_preds, average='macro')
        scores.append({'accuracy': acc, 'f1': f1})
        print(f"\nğŸ“Š Fold {fold + 1} Best: Accuracy={acc:.4f}, Macro F1={f1:.4f}")
        
        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del model
        torch.cuda.empty_cache()
    
    # =============================================================================
    # çµæœã‚µãƒãƒªãƒ¼
    # =============================================================================
    print("\n" + "=" * 60)
    print("ğŸ“Š çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)
    
    mean_acc = np.mean([s['accuracy'] for s in scores])
    mean_f1 = np.mean([s['f1'] for s in scores])
    std_acc = np.std([s['accuracy'] for s in scores])
    std_f1 = np.std([s['f1'] for s in scores])
    
    print(f"\nğŸ¯ CVçµæœ:")
    print(f"   Accuracy: {mean_acc:.4f} Â± {std_acc:.4f}")
    print(f"   Macro F1: {mean_f1:.4f} Â± {std_f1:.4f}")
    
    print(f"\nğŸ“‹ Classification Report (OOF):")
    print(classification_report(y, oof_preds, digits=4))
    
    # ãƒ†ã‚¹ãƒˆäºˆæ¸¬ï¼ˆå¤šæ•°æ±ºï¼‰
    test_class = np.argmax(test_preds, axis=1) + 1
    print(f"\nãƒ†ã‚¹ãƒˆäºˆæ¸¬ã®åˆ†å¸ƒ:")
    print(pd.Series(test_class).value_counts().sort_index())
    
    # ä¿å­˜
    submission = pd.DataFrame({
        'id': range(len(test)),
        'Rating': test_class
    })
    submission.to_csv(f'{DATA_DIR}/submission_bert.csv', index=False)
    print(f"\nğŸ’¾ äºˆæ¸¬çµæœã‚’ä¿å­˜: {DATA_DIR}/submission_bert.csv")
    
    # OOFäºˆæ¸¬ã‚‚ä¿å­˜
    np.save(f'{DATA_DIR}/oof_bert.npy', oof_preds)
    print(f"ğŸ’¾ OOFäºˆæ¸¬ã‚’ä¿å­˜: {DATA_DIR}/oof_bert.npy")
    
    print("\n" + "=" * 60)
    print("âœ… 3.4 BERT å®Œäº†!")
    print("=" * 60)

if __name__ == '__main__':
    main()
